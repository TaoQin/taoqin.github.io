% # Tao Qin (Áß¶Ê∂õ)
# Vice President at Zhongguangcun Academy
Previously Partner Research Manager at Microsoft Research, leading the MSR AI for Science Asia team  

---

## üî¨ Research Interests
- **AI for Science**: Science Foundation Models, Molecular Modeling/Drug Discovery, Biochemistry, Material Design
- **Deep Learning**: LLMs, Machine Translation, Healthcare, Speech Synthesis/Recognition, Music Understanding/Composition
- **Reinforcement Learning**: RL for Science, Games, and Real-world Applications

---

## üöÄ Recent Updates
- Accelerating protein engineering with fitness landscape modeling and RL. **Nature Machine Intelligence** 2025. [[paper]](https://www.nature.com/articles/s42256-025-01103-w) [[Wechat article]](https://mp.weixin.qq.com/s/C65j-x6LHn_segjRkpdU0g)
- E2Former: An Efficient and Equivariant Transformer with Linear-Scaling Tensor Products. **NeurIPS** 2025.
- Chain-of-Model Learning for Language Model. **NeurIPS** 2025.
- High-Quality Zero-Shot Podcast Generation. **NeurIPS** 2025.
- **BioGPT**: GPT model for biomedical domain [[Paper]](https://arxiv.org/abs/2210.10341) [[Code/Model]](https://github.com/microsoft/BioGPT)
- MPNet generates most effective sentence embeddings among ~40 pretrained models
- **TD3 with Reverse KL Regularizer** selected as ICDM 2022 Best Student Paper Award runner-up
- Impact of Large Language Models on Scientific Discovery (Arxiv 2023)

---

## üèÜ Featured Work
### üÄÑ Suphx Mahjong AI
First 10 DAN AI for Mahjong based on deep reinforcement learning with novel techniques:
- Global reward prediction
- Oracle guiding
- Run-time policy adaptation  
[[News]](https://www.microsoft.com/en-us/research/blog/suphx-achieving-new-milestones-in-the-game-of-mahjong/) [[Paper]](https://arxiv.org/abs/2003.13590)  
[Review by human players (Japanese)](https://note.com/kokoroe/n/n9e6c0d1b5d3a)

### üó£Ô∏è FastSpeech series
Novel feed-forward networks for parallel mel-spectrogram generation:
- 270x faster mel-spectrogram generation
- 38x faster end-to-end speech synthesis  
Integrated into Azure TTS with 70+ languages/locales and 200+ voices  
[[News 1]](https://www.microsoft.com/en-us/research/blog/fastspeech-2/) [[News 2]](https://azure.microsoft.com/en-us/blog/neural-text-to-speech-now-supports-49-languages/)

### üåê Machine Translation Achievements
- Achieved **human parity** in Chinese-English translation (2018)
- Won **1st place in 8 translation tasks** at WMT 2019
- Dual learning integrated into Microsoft Translator for multiple languages
- **MASS algorithm** - first pre-training model for sequence-to-sequence generation [[Code]](https://github.com/microsoft/MASS) [[News]](https://www.microsoft.com/en-us/research/blog/microsoft-machines-set-new-standards-in-chinese-to-english-machine-translation/)

---
<!-- 
## üì£ We Are Hiring!
Seeking all levels of researchers with:
- Strong coding skills
- Passion for machine learning research in natural science problems  
üìß Contact: `qintao@bjzgca.edu.cn`

---
-->

## üìö Books & Surveys
### Books
- **Dual Learning** (Springer 2020)  
  Framework leveraging structural duality between AI tasks. Covers dual reconstruction, joint-probability equation, and applications in machine translation, image-to-image translation, speech processing, etc.

### Surveys
- **A Survey on Neural Speech Synthesis** (Arxiv 2021)
- **A Survey on Low-Resource Neural Machine Translation** (IJCAI 2021)
- **Generalizing to Unseen Domains: A Survey on Domain Generalization** (IJCAI 2021)

---

## üß™ Foundation Models
- **BioGPT**: Generative Pre-trained Transformer for biomedical text [[Paper]](https://www.biorxiv.org/content/10.1101/2022.06.24.497479v1) [[Code]](https://github.com/microsoft/BioGPT)
- **SPRoBERTa**: Protein Embedding Learning with Local Fragment Modeling [[Paper]](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbab564/6491404)
- **Transcormer**: Transformer for Sentence Scoring (NeurIPS 2022)
- **NAS-BERT**: Task-Agnostic BERT Compression (KDD 2021)
- **MusicBERT**: Symbolic Music Understanding (ACL 2021)
- **MPNet**: Masked and Permuted Pre-training (NeurIPS 2020) [[Code]](https://github.com/microsoft/MPNet)

---

## üìä Open Source & Datasets
- **R-Drop**: Regularized Dropout for Neural Networks [[Code]](https://github.com/dropreg/R-Drop) (NeurIPS 2021)
- **Fully Parameterized Quantile Function** for RL [[Code]](https://github.com/microsoft/fully-parameterized-quantile-function) (NeurIPS 2019)
- **Incorporating BERT into NMT** [[Code]](https://github.com/bert-nmt/bert-nmt) (ICLR 2020)
- **Efficient Training of BERT** [[Code]](https://github.com/microsoft/progressively-stacking-bert) (ICML 2019)
- **LightRNN**: Memory/Computation-Efficient RNNs [[Code]](https://github.com/Microsoft/LightRNN)
- **Microsoft Learning to Rank Datasets** [[Dataset]](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/)

---

## üì∞ Blogs & Articles
- [AutoML: Discovering the best neural architectures](https://www.microsoft.com/en-us/research/blog/automl-discovering-the-best-neural-architectures/)
- [Learning to teach: Mutually enhanced learning](https://www.microsoft.com/en-us/research/blog/learning-to-teach-mutually-enhanced-learning-and-teaching-for-artificial-intelligence/)
- [ËÆ≠ÁªÉÂèØËß£Èáä„ÄÅÂèØÂéãÁº©„ÄÅÈ´òÂáÜÁ°ÆÁéáÁöÑLSTM](https://zhuanlan.zhihu.com/p/42169559)
- [We matched human performance in Chinese-English translation](https://www.microsoft.com/en-us/research/blog/microsoft-machines-set-new-milestones-in-chinese-to-english-machine-translation/)
- [ÂØπÂÅ∂Â≠¶‰π†](https://zhuanlan.zhihu.com/p/34592532)

---

## üéì Education & Affiliations
- **PhD & Bachelor**: Tsinghua University
- **Adjunct Professor** (PhD advisor): University of Science and Technology of China
- **Senior Member**: ACM & IEEE

---

## üìù Publications

### 2023
- **FABind**: Fast Accurate Protein-Ligand Binding (NeurIPS)
- **SMT-DTA**: Drug-Target Affinity Prediction (Briefings in Bioinformatics)
- **Pre-training Antibody Language Models** (KDD)
- **Dual-view Molecular Pre-training** (KDD)
- **Retrosynthetic Planning** (ICML)
- **De Novo Molecular Generation** (ICLR)
- **O-GNN**: Incorporating Ring Priors (ICLR)

### 2022
- **BioGPT** (Briefings in Bioinformatics) [[Code]](https://github.com/microsoft/BioGPT)
- **TD3 with Reverse KL** (ICDM Best Student Paper Runner-up)
- **SPRoBERTa** (Briefings in Bioinformatics)
- **Unified 2D/3D Molecular Pre-training** (KDD)
- **Direct Molecular Conformation Generation** (TMLR)

### 2021 & Earlier
- **Making Better Decisions in Continuous Control** (ICLR 2023)
- **Tiered RL** (NeurIPS 2022)
- **Museformer** for Music Generation (NeurIPS 2022)
- **Suphx Mahjong AI** (arXiv 2020)
- **Deliberation Networks** (NIPS 2017)
- **Dual Learning** (NIPS 2016)

**[Full Publication List](https://scholar.google.com/citations?hl=en&user=Bl4SRU0AAAAJ)**

---

## üí¨ Talks & Tutorials
- Tutorial: Recent Advances in Neural Speech Synthesis (ICASSP 2022)
- Tutorial: Neural Speech Synthesis (IJCAI 2021)
- Tutorial: Dual Learning (IJCAI 2019, ACML 2018)
- Keynote: Neural Machine Translation (ACML 2018)
- Workshop: Multi-output Learning
- Efficient NMT (GTC China 2018)

---

## üéµ Music Understanding & Generation
- **MusicBERT**: Symbolic Music Understanding
- **PDAugment**: Automatic Lyrics Transcription
- **SongMASS**: Automatic Song Writing
- **DeepRapper**: Rap Generation
- **TeleMelody**: Melody Generation
- **PopMAG**: Music Accompaniment
- **HiFiSinger**: High-Fidelity Singing Synthesis

---

## üì´ Contact
**MSR AI for Science Asia Team**  
Microsoft Research Asia  
üìß `taoqin@microsoft.com`  
[Team Website](https://www.microsoft.com/en-us/research/group/ai-for-science-asia/)

> *"We are developing AI to accelerate scientific discovery - from molecular design to protein engineering and drug discovery."*





